{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 - Week 1 - Karthick Krishna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "\n",
    "###### Describe a situation or problem from your job, everyday life, current events, etc., for which a classification model would be appropriate. List some (up to 5) predictors that you might use. \n",
    "\n",
    "    I am an Analyst at Mindtree Limited. Currently, I work on Marketing Analytics and Ad Analytics.I work for one of the world's largest Search Engine Platform provider on the Advertiser data and User level data.I use Python for analysis and used the Scikit Learn package in Python. Recently I worked on segregating the Customers(also known as Advertisers) into five categories based on a lot of different KPI's. I performed Regression Analysis on the following predictors to identify and classify the type of Advertiser based on lots of factors. \n",
    "\n",
    " \n",
    "\n",
    "    Few of those KPI's(predictors) are as follows,\n",
    "\n",
    "     1. The Impression gained by the advertiser using the platform\n",
    "     2. Click gained by the advertiser using the platform\n",
    "     3. Spend/Revenue of the Advertiser on the Platform\n",
    "     4. Cost per Click (CPC) \n",
    "     5. Click through Rate (CTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 (Question 1 and 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### On an overall level \"rbfdot\" Kernel has performed extremly well with an accuracy of \"98.471\" and C(lambda) of 1000\n",
    "\n",
    "We see a different kind of output when we split the data (70%-train and 30%-test) and it's mentioned after this piece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### My approach to the given problem:\n",
    "\n",
    "    In this problem, I've used four different Kernel function types and seven different Cost function values. An iterative process of first selecting a Kernel function type followed by selecting a Cost function value, later ksvm is applied and weights, bias values, and Accuracy are calculated for a specific combination of Kernel and Cost function. This process goes on until all the combination is completed. In the end, I create a Dataframe and place all the values in it ordering on Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equation based on the maximum accuracy produced by the model\n",
    "\n",
    "    y = (-52.963 x A1) + (-20.619 x A2) + (-55.471 x A3) + (123.982 x A8) + (86.393 x A9) + (-93.044 x A10) + (99.034 x A11) + (-66.936 x A12) + (-75.808 x A14) + (100.064 x A15) - 0.729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### My understanding of the output\n",
    "\n",
    "The accuracy looks extremely well. Seriously, if I wasn't into Data Science or Data Analytics I'll be jumping in joy and dancing around for the accuracy that I've got. Unfortunately, I'm aware of a concept called ***Overfitting*** so I cannot enjoy the result that has been generated. The model calculated predicted accuracy on data was trained in, thus fit that data too well. Thus, we cannot be happy with this output.\n",
    "\n",
    "**Post this code I've performed the same but by splitting the data into Train and Test (70% and 30%). Kindly, view that to understand how Overfitting is handled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer from peer guy:\n",
    "\n",
    "**The hyper-parameter C, also known as lambda is used to weigh the importance of having a large margin\n",
    "v.s. correctly classifying data points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Kernel</th><th scope=col>Cost Value</th><th scope=col>Accuracy</th><th scope=col>a0</th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>6</th><td>rbfdot    </td><td>1000.000  </td><td>98.471    </td><td>-0.729    </td><td>-52.963   </td><td>-20.619   </td><td>-55.471   </td><td>123.982   </td><td>86.393    </td><td>-93.044   </td><td>99.034    </td><td>-66.936   </td><td>-75.808   </td><td>100.064   </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>rbfdot    </td><td> 100.000  </td><td>95.413    </td><td>-0.728    </td><td>-18.784   </td><td>-35.719   </td><td> -8.228   </td><td> 55.509   </td><td>51.183    </td><td>-26.201   </td><td>19.764    </td><td>-24.521   </td><td>-57.518   </td><td> 53.789   </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>rbfdot    </td><td>  10.000  </td><td>91.896    </td><td>-0.439    </td><td> -3.051   </td><td>-17.776   </td><td>  3.521   </td><td> 27.046   </td><td>32.357    </td><td>-12.241   </td><td>16.593    </td><td> -9.436   </td><td>-32.945   </td><td> 37.515   </td></tr>\n",
       "\t<tr><th scope=row>13</th><td>anovadot  </td><td> 100.000  </td><td>90.673    </td><td>-1.174    </td><td>  0.019   </td><td>-22.498   </td><td>-28.051   </td><td> -2.358   </td><td> 2.536    </td><td> -1.122   </td><td>-3.115    </td><td> -0.046   </td><td>-16.445   </td><td> 14.825   </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>anovadot  </td><td>1000.000  </td><td>90.673    </td><td>-8.831    </td><td>  0.133   </td><td>-29.447   </td><td>-69.102   </td><td>-21.960   </td><td> 2.657    </td><td> -1.687   </td><td>-5.867    </td><td> -0.011   </td><td>-42.511   </td><td>  9.881   </td></tr>\n",
       "\t<tr><th scope=row>11</th><td>anovadot  </td><td>  10.000  </td><td>87.309    </td><td>-0.029    </td><td>  0.011   </td><td> -8.131   </td><td>-10.580   </td><td>  3.779   </td><td> 2.222    </td><td> -0.359   </td><td> 4.490    </td><td>  0.002   </td><td> -7.895   </td><td> 18.973   </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>rbfdot    </td><td>   1.000  </td><td>87.156    </td><td>-0.416    </td><td>  0.391   </td><td> -1.944   </td><td>  4.341   </td><td> 14.824   </td><td>32.454    </td><td> -7.266   </td><td>19.416    </td><td> -5.167   </td><td>-16.303   </td><td> 28.563   </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>anovadot  </td><td>   1.000  </td><td>86.391    </td><td>-0.375    </td><td>  0.002   </td><td> -1.539   </td><td> -0.900   </td><td>  0.698   </td><td> 2.050    </td><td> -0.027   </td><td> 0.768    </td><td>  0.001   </td><td> -2.719   </td><td> 18.690   </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>vanilladot</td><td>   0.010  </td><td>86.391    </td><td>-0.082    </td><td>  0.000   </td><td> -0.001   </td><td>  0.001   </td><td>  0.007   </td><td> 0.992    </td><td> -0.004   </td><td> 0.007    </td><td> -0.001   </td><td> -0.002   </td><td>  0.105   </td></tr>\n",
       "\t<tr><th scope=row>16</th><td>polydot   </td><td>   0.010  </td><td>86.391    </td><td>-0.082    </td><td>  0.000   </td><td> -0.001   </td><td>  0.001   </td><td>  0.007   </td><td> 0.992    </td><td> -0.004   </td><td> 0.007    </td><td> -0.001   </td><td> -0.002   </td><td>  0.105   </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>polydot   </td><td>   0.100  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.001   </td><td>  0.003   </td><td> 1.004    </td><td> -0.003   </td><td> 0.000    </td><td>  0.000   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>18</th><td>polydot   </td><td>   1.000  </td><td>86.391    </td><td>-0.081    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td> -0.001   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>polydot   </td><td>  10.000  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td> -0.001   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>20</th><td>polydot   </td><td> 100.000  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td> -0.001   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>22</th><td>vanilladot</td><td>   0.100  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.004    </td><td> -0.003   </td><td> 0.000    </td><td>  0.000   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>23</th><td>vanilladot</td><td>   1.000  </td><td>86.391    </td><td>-0.081    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td> -0.001   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>24</th><td>vanilladot</td><td>  10.000  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td>  0.000   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>25</th><td>vanilladot</td><td> 100.000  </td><td>86.391    </td><td>-0.082    </td><td> -0.001   </td><td> -0.001   </td><td> -0.002   </td><td>  0.003   </td><td> 1.005    </td><td> -0.003   </td><td> 0.000    </td><td> -0.001   </td><td> -0.001   </td><td>  0.106   </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>anovadot  </td><td>   0.010  </td><td>86.239    </td><td>-0.150    </td><td> -0.008   </td><td>  0.024   </td><td>  0.025   </td><td>  0.223   </td><td> 1.811    </td><td> -0.094   </td><td> 0.297    </td><td>  0.007   </td><td> -0.164   </td><td>  0.516   </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>anovadot  </td><td>   0.100  </td><td>86.239    </td><td>-0.039    </td><td>  0.000   </td><td> -0.155   </td><td> -0.085   </td><td>  0.071   </td><td> 2.040    </td><td> -0.002   </td><td> 0.080    </td><td>  0.000   </td><td> -0.275   </td><td>  1.866   </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>polydot   </td><td>1000.000  </td><td>86.239    </td><td>-0.070    </td><td>  0.000   </td><td> -0.001   </td><td>  0.000   </td><td>  0.000   </td><td> 0.998    </td><td>  0.000   </td><td> 0.001    </td><td>  0.000   </td><td>  0.000   </td><td>  0.001   </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>vanilladot</td><td>1000.000  </td><td>86.239    </td><td>-0.070    </td><td>  0.000   </td><td>  0.001   </td><td>  0.001   </td><td>  0.001   </td><td> 0.999    </td><td> -0.001   </td><td> 0.001    </td><td> -0.001   </td><td>  0.001   </td><td>  0.001   </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>rbfdot    </td><td>   0.100  </td><td>85.933    </td><td>-0.498    </td><td>  0.439   </td><td>  2.596   </td><td>  2.904   </td><td>  7.351   </td><td>18.092    </td><td> -4.184   </td><td> 7.105    </td><td> -0.867   </td><td> -2.683   </td><td>  7.152   </td></tr>\n",
       "\t<tr><th scope=row>1</th><td>vanilladot</td><td>   0.001  </td><td>83.792    </td><td> 0.223    </td><td> -0.002   </td><td>  0.032   </td><td>  0.047   </td><td>  0.111   </td><td> 0.375    </td><td> -0.202   </td><td> 0.170    </td><td> -0.005   </td><td> -0.025   </td><td>  0.081   </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>polydot   </td><td>   0.001  </td><td>83.792    </td><td> 0.223    </td><td> -0.002   </td><td>  0.032   </td><td>  0.047   </td><td>  0.111   </td><td> 0.375    </td><td> -0.202   </td><td> 0.170    </td><td> -0.005   </td><td> -0.025   </td><td>  0.081   </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>anovadot  </td><td>   0.001  </td><td>58.869    </td><td> 0.408    </td><td> -0.005   </td><td>  0.073   </td><td>  0.090   </td><td>  0.179   </td><td> 0.413    </td><td> -0.240   </td><td> 0.233    </td><td> -0.008   </td><td> -0.048   </td><td>  0.102   </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>rbfdot    </td><td>   0.010  </td><td>56.728    </td><td> 0.379    </td><td>  0.194   </td><td>  0.860   </td><td>  0.963   </td><td>  1.831   </td><td> 4.127    </td><td> -2.396   </td><td> 2.332    </td><td> -0.100   </td><td> -0.575   </td><td>  1.016   </td></tr>\n",
       "\t<tr><th scope=row>27</th><td>rbfdot    </td><td>   0.001  </td><td>54.740    </td><td> 0.939    </td><td>  0.019   </td><td>  0.086   </td><td>  0.098   </td><td>  0.183   </td><td> 0.413    </td><td> -0.240   </td><td> 0.233    </td><td> -0.010   </td><td> -0.057   </td><td>  0.102   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & Kernel & Cost Value & Accuracy & a0 & V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10\\\\\n",
       "\\hline\n",
       "\t6 & rbfdot     & 1000.000   & 98.471     & -0.729     & -52.963    & -20.619    & -55.471    & 123.982    & 86.393     & -93.044    & 99.034     & -66.936    & -75.808    & 100.064   \\\\\n",
       "\t5 & rbfdot     &  100.000   & 95.413     & -0.728     & -18.784    & -35.719    &  -8.228    &  55.509    & 51.183     & -26.201    & 19.764     & -24.521    & -57.518    &  53.789   \\\\\n",
       "\t4 & rbfdot     &   10.000   & 91.896     & -0.439     &  -3.051    & -17.776    &   3.521    &  27.046    & 32.357     & -12.241    & 16.593     &  -9.436    & -32.945    &  37.515   \\\\\n",
       "\t13 & anovadot   &  100.000   & 90.673     & -1.174     &   0.019    & -22.498    & -28.051    &  -2.358    &  2.536     &  -1.122    & -3.115     &  -0.046    & -16.445    &  14.825   \\\\\n",
       "\t14 & anovadot   & 1000.000   & 90.673     & -8.831     &   0.133    & -29.447    & -69.102    & -21.960    &  2.657     &  -1.687    & -5.867     &  -0.011    & -42.511    &   9.881   \\\\\n",
       "\t11 & anovadot   &   10.000   & 87.309     & -0.029     &   0.011    &  -8.131    & -10.580    &   3.779    &  2.222     &  -0.359    &  4.490     &   0.002    &  -7.895    &  18.973   \\\\\n",
       "\t3 & rbfdot     &    1.000   & 87.156     & -0.416     &   0.391    &  -1.944    &   4.341    &  14.824    & 32.454     &  -7.266    & 19.416     &  -5.167    & -16.303    &  28.563   \\\\\n",
       "\t10 & anovadot   &    1.000   & 86.391     & -0.375     &   0.002    &  -1.539    &  -0.900    &   0.698    &  2.050     &  -0.027    &  0.768     &   0.001    &  -2.719    &  18.690   \\\\\n",
       "\t12 & vanilladot &    0.010   & 86.391     & -0.082     &   0.000    &  -0.001    &   0.001    &   0.007    &  0.992     &  -0.004    &  0.007     &  -0.001    &  -0.002    &   0.105   \\\\\n",
       "\t16 & polydot    &    0.010   & 86.391     & -0.082     &   0.000    &  -0.001    &   0.001    &   0.007    &  0.992     &  -0.004    &  0.007     &  -0.001    &  -0.002    &   0.105   \\\\\n",
       "\t17 & polydot    &    0.100   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.001    &   0.003    &  1.004     &  -0.003    &  0.000     &   0.000    &  -0.001    &   0.106   \\\\\n",
       "\t18 & polydot    &    1.000   & 86.391     & -0.081     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &  -0.001    &  -0.001    &   0.106   \\\\\n",
       "\t19 & polydot    &   10.000   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &  -0.001    &  -0.001    &   0.106   \\\\\n",
       "\t20 & polydot    &  100.000   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &  -0.001    &  -0.001    &   0.106   \\\\\n",
       "\t22 & vanilladot &    0.100   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.004     &  -0.003    &  0.000     &   0.000    &  -0.001    &   0.106   \\\\\n",
       "\t23 & vanilladot &    1.000   & 86.391     & -0.081     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &  -0.001    &  -0.001    &   0.106   \\\\\n",
       "\t24 & vanilladot &   10.000   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &   0.000    &  -0.001    &   0.106   \\\\\n",
       "\t25 & vanilladot &  100.000   & 86.391     & -0.082     &  -0.001    &  -0.001    &  -0.002    &   0.003    &  1.005     &  -0.003    &  0.000     &  -0.001    &  -0.001    &   0.106   \\\\\n",
       "\t8 & anovadot   &    0.010   & 86.239     & -0.150     &  -0.008    &   0.024    &   0.025    &   0.223    &  1.811     &  -0.094    &  0.297     &   0.007    &  -0.164    &   0.516   \\\\\n",
       "\t9 & anovadot   &    0.100   & 86.239     & -0.039     &   0.000    &  -0.155    &  -0.085    &   0.071    &  2.040     &  -0.002    &  0.080     &   0.000    &  -0.275    &   1.866   \\\\\n",
       "\t21 & polydot    & 1000.000   & 86.239     & -0.070     &   0.000    &  -0.001    &   0.000    &   0.000    &  0.998     &   0.000    &  0.001     &   0.000    &   0.000    &   0.001   \\\\\n",
       "\t26 & vanilladot & 1000.000   & 86.239     & -0.070     &   0.000    &   0.001    &   0.001    &   0.001    &  0.999     &  -0.001    &  0.001     &  -0.001    &   0.001    &   0.001   \\\\\n",
       "\t2 & rbfdot     &    0.100   & 85.933     & -0.498     &   0.439    &   2.596    &   2.904    &   7.351    & 18.092     &  -4.184    &  7.105     &  -0.867    &  -2.683    &   7.152   \\\\\n",
       "\t1 & vanilladot &    0.001   & 83.792     &  0.223     &  -0.002    &   0.032    &   0.047    &   0.111    &  0.375     &  -0.202    &  0.170     &  -0.005    &  -0.025    &   0.081   \\\\\n",
       "\t15 & polydot    &    0.001   & 83.792     &  0.223     &  -0.002    &   0.032    &   0.047    &   0.111    &  0.375     &  -0.202    &  0.170     &  -0.005    &  -0.025    &   0.081   \\\\\n",
       "\t7 & anovadot   &    0.001   & 58.869     &  0.408     &  -0.005    &   0.073    &   0.090    &   0.179    &  0.413     &  -0.240    &  0.233     &  -0.008    &  -0.048    &   0.102   \\\\\n",
       "\t28 & rbfdot     &    0.010   & 56.728     &  0.379     &   0.194    &   0.860    &   0.963    &   1.831    &  4.127     &  -2.396    &  2.332     &  -0.100    &  -0.575    &   1.016   \\\\\n",
       "\t27 & rbfdot     &    0.001   & 54.740     &  0.939     &   0.019    &   0.086    &   0.098    &   0.183    &  0.413     &  -0.240    &  0.233     &  -0.010    &  -0.057    &   0.102   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Kernel | Cost Value | Accuracy | a0 | V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 6 | rbfdot     | 1000.000   | 98.471     | -0.729     | -52.963    | -20.619    | -55.471    | 123.982    | 86.393     | -93.044    | 99.034     | -66.936    | -75.808    | 100.064    |\n",
       "| 5 | rbfdot     |  100.000   | 95.413     | -0.728     | -18.784    | -35.719    |  -8.228    |  55.509    | 51.183     | -26.201    | 19.764     | -24.521    | -57.518    |  53.789    |\n",
       "| 4 | rbfdot     |   10.000   | 91.896     | -0.439     |  -3.051    | -17.776    |   3.521    |  27.046    | 32.357     | -12.241    | 16.593     |  -9.436    | -32.945    |  37.515    |\n",
       "| 13 | anovadot   |  100.000   | 90.673     | -1.174     |   0.019    | -22.498    | -28.051    |  -2.358    |  2.536     |  -1.122    | -3.115     |  -0.046    | -16.445    |  14.825    |\n",
       "| 14 | anovadot   | 1000.000   | 90.673     | -8.831     |   0.133    | -29.447    | -69.102    | -21.960    |  2.657     |  -1.687    | -5.867     |  -0.011    | -42.511    |   9.881    |\n",
       "| 11 | anovadot   |   10.000   | 87.309     | -0.029     |   0.011    |  -8.131    | -10.580    |   3.779    |  2.222     |  -0.359    |  4.490     |   0.002    |  -7.895    |  18.973    |\n",
       "| 3 | rbfdot     |    1.000   | 87.156     | -0.416     |   0.391    |  -1.944    |   4.341    |  14.824    | 32.454     |  -7.266    | 19.416     |  -5.167    | -16.303    |  28.563    |\n",
       "| 10 | anovadot   |    1.000   | 86.391     | -0.375     |   0.002    |  -1.539    |  -0.900    |   0.698    |  2.050     |  -0.027    |  0.768     |   0.001    |  -2.719    |  18.690    |\n",
       "| 12 | vanilladot |    0.010   | 86.391     | -0.082     |   0.000    |  -0.001    |   0.001    |   0.007    |  0.992     |  -0.004    |  0.007     |  -0.001    |  -0.002    |   0.105    |\n",
       "| 16 | polydot    |    0.010   | 86.391     | -0.082     |   0.000    |  -0.001    |   0.001    |   0.007    |  0.992     |  -0.004    |  0.007     |  -0.001    |  -0.002    |   0.105    |\n",
       "| 17 | polydot    |    0.100   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.001    |   0.003    |  1.004     |  -0.003    |  0.000     |   0.000    |  -0.001    |   0.106    |\n",
       "| 18 | polydot    |    1.000   | 86.391     | -0.081     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |  -0.001    |  -0.001    |   0.106    |\n",
       "| 19 | polydot    |   10.000   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |  -0.001    |  -0.001    |   0.106    |\n",
       "| 20 | polydot    |  100.000   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |  -0.001    |  -0.001    |   0.106    |\n",
       "| 22 | vanilladot |    0.100   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.004     |  -0.003    |  0.000     |   0.000    |  -0.001    |   0.106    |\n",
       "| 23 | vanilladot |    1.000   | 86.391     | -0.081     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |  -0.001    |  -0.001    |   0.106    |\n",
       "| 24 | vanilladot |   10.000   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |   0.000    |  -0.001    |   0.106    |\n",
       "| 25 | vanilladot |  100.000   | 86.391     | -0.082     |  -0.001    |  -0.001    |  -0.002    |   0.003    |  1.005     |  -0.003    |  0.000     |  -0.001    |  -0.001    |   0.106    |\n",
       "| 8 | anovadot   |    0.010   | 86.239     | -0.150     |  -0.008    |   0.024    |   0.025    |   0.223    |  1.811     |  -0.094    |  0.297     |   0.007    |  -0.164    |   0.516    |\n",
       "| 9 | anovadot   |    0.100   | 86.239     | -0.039     |   0.000    |  -0.155    |  -0.085    |   0.071    |  2.040     |  -0.002    |  0.080     |   0.000    |  -0.275    |   1.866    |\n",
       "| 21 | polydot    | 1000.000   | 86.239     | -0.070     |   0.000    |  -0.001    |   0.000    |   0.000    |  0.998     |   0.000    |  0.001     |   0.000    |   0.000    |   0.001    |\n",
       "| 26 | vanilladot | 1000.000   | 86.239     | -0.070     |   0.000    |   0.001    |   0.001    |   0.001    |  0.999     |  -0.001    |  0.001     |  -0.001    |   0.001    |   0.001    |\n",
       "| 2 | rbfdot     |    0.100   | 85.933     | -0.498     |   0.439    |   2.596    |   2.904    |   7.351    | 18.092     |  -4.184    |  7.105     |  -0.867    |  -2.683    |   7.152    |\n",
       "| 1 | vanilladot |    0.001   | 83.792     |  0.223     |  -0.002    |   0.032    |   0.047    |   0.111    |  0.375     |  -0.202    |  0.170     |  -0.005    |  -0.025    |   0.081    |\n",
       "| 15 | polydot    |    0.001   | 83.792     |  0.223     |  -0.002    |   0.032    |   0.047    |   0.111    |  0.375     |  -0.202    |  0.170     |  -0.005    |  -0.025    |   0.081    |\n",
       "| 7 | anovadot   |    0.001   | 58.869     |  0.408     |  -0.005    |   0.073    |   0.090    |   0.179    |  0.413     |  -0.240    |  0.233     |  -0.008    |  -0.048    |   0.102    |\n",
       "| 28 | rbfdot     |    0.010   | 56.728     |  0.379     |   0.194    |   0.860    |   0.963    |   1.831    |  4.127     |  -2.396    |  2.332     |  -0.100    |  -0.575    |   1.016    |\n",
       "| 27 | rbfdot     |    0.001   | 54.740     |  0.939     |   0.019    |   0.086    |   0.098    |   0.183    |  0.413     |  -0.240    |  0.233     |  -0.010    |  -0.057    |   0.102    |\n",
       "\n"
      ],
      "text/plain": [
       "   Kernel     Cost Value Accuracy a0     V1      V2      V3      V4      V5    \n",
       "6  rbfdot     1000.000   98.471   -0.729 -52.963 -20.619 -55.471 123.982 86.393\n",
       "5  rbfdot      100.000   95.413   -0.728 -18.784 -35.719  -8.228  55.509 51.183\n",
       "4  rbfdot       10.000   91.896   -0.439  -3.051 -17.776   3.521  27.046 32.357\n",
       "13 anovadot    100.000   90.673   -1.174   0.019 -22.498 -28.051  -2.358  2.536\n",
       "14 anovadot   1000.000   90.673   -8.831   0.133 -29.447 -69.102 -21.960  2.657\n",
       "11 anovadot     10.000   87.309   -0.029   0.011  -8.131 -10.580   3.779  2.222\n",
       "3  rbfdot        1.000   87.156   -0.416   0.391  -1.944   4.341  14.824 32.454\n",
       "10 anovadot      1.000   86.391   -0.375   0.002  -1.539  -0.900   0.698  2.050\n",
       "12 vanilladot    0.010   86.391   -0.082   0.000  -0.001   0.001   0.007  0.992\n",
       "16 polydot       0.010   86.391   -0.082   0.000  -0.001   0.001   0.007  0.992\n",
       "17 polydot       0.100   86.391   -0.082  -0.001  -0.001  -0.001   0.003  1.004\n",
       "18 polydot       1.000   86.391   -0.081  -0.001  -0.001  -0.002   0.003  1.005\n",
       "19 polydot      10.000   86.391   -0.082  -0.001  -0.001  -0.002   0.003  1.005\n",
       "20 polydot     100.000   86.391   -0.082  -0.001  -0.001  -0.002   0.003  1.005\n",
       "22 vanilladot    0.100   86.391   -0.082  -0.001  -0.001  -0.002   0.003  1.004\n",
       "23 vanilladot    1.000   86.391   -0.081  -0.001  -0.001  -0.002   0.003  1.005\n",
       "24 vanilladot   10.000   86.391   -0.082  -0.001  -0.001  -0.002   0.003  1.005\n",
       "25 vanilladot  100.000   86.391   -0.082  -0.001  -0.001  -0.002   0.003  1.005\n",
       "8  anovadot      0.010   86.239   -0.150  -0.008   0.024   0.025   0.223  1.811\n",
       "9  anovadot      0.100   86.239   -0.039   0.000  -0.155  -0.085   0.071  2.040\n",
       "21 polydot    1000.000   86.239   -0.070   0.000  -0.001   0.000   0.000  0.998\n",
       "26 vanilladot 1000.000   86.239   -0.070   0.000   0.001   0.001   0.001  0.999\n",
       "2  rbfdot        0.100   85.933   -0.498   0.439   2.596   2.904   7.351 18.092\n",
       "1  vanilladot    0.001   83.792    0.223  -0.002   0.032   0.047   0.111  0.375\n",
       "15 polydot       0.001   83.792    0.223  -0.002   0.032   0.047   0.111  0.375\n",
       "7  anovadot      0.001   58.869    0.408  -0.005   0.073   0.090   0.179  0.413\n",
       "28 rbfdot        0.010   56.728    0.379   0.194   0.860   0.963   1.831  4.127\n",
       "27 rbfdot        0.001   54.740    0.939   0.019   0.086   0.098   0.183  0.413\n",
       "   V6      V7     V8      V9      V10    \n",
       "6  -93.044 99.034 -66.936 -75.808 100.064\n",
       "5  -26.201 19.764 -24.521 -57.518  53.789\n",
       "4  -12.241 16.593  -9.436 -32.945  37.515\n",
       "13  -1.122 -3.115  -0.046 -16.445  14.825\n",
       "14  -1.687 -5.867  -0.011 -42.511   9.881\n",
       "11  -0.359  4.490   0.002  -7.895  18.973\n",
       "3   -7.266 19.416  -5.167 -16.303  28.563\n",
       "10  -0.027  0.768   0.001  -2.719  18.690\n",
       "12  -0.004  0.007  -0.001  -0.002   0.105\n",
       "16  -0.004  0.007  -0.001  -0.002   0.105\n",
       "17  -0.003  0.000   0.000  -0.001   0.106\n",
       "18  -0.003  0.000  -0.001  -0.001   0.106\n",
       "19  -0.003  0.000  -0.001  -0.001   0.106\n",
       "20  -0.003  0.000  -0.001  -0.001   0.106\n",
       "22  -0.003  0.000   0.000  -0.001   0.106\n",
       "23  -0.003  0.000  -0.001  -0.001   0.106\n",
       "24  -0.003  0.000   0.000  -0.001   0.106\n",
       "25  -0.003  0.000  -0.001  -0.001   0.106\n",
       "8   -0.094  0.297   0.007  -0.164   0.516\n",
       "9   -0.002  0.080   0.000  -0.275   1.866\n",
       "21   0.000  0.001   0.000   0.000   0.001\n",
       "26  -0.001  0.001  -0.001   0.001   0.001\n",
       "2   -4.184  7.105  -0.867  -2.683   7.152\n",
       "1   -0.202  0.170  -0.005  -0.025   0.081\n",
       "15  -0.202  0.170  -0.005  -0.025   0.081\n",
       "7   -0.240  0.233  -0.008  -0.048   0.102\n",
       "28  -2.396  2.332  -0.100  -0.575   1.016\n",
       "27  -0.240  0.233  -0.010  -0.057   0.102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the needed packages\n",
    "options(scipen = 999)\n",
    "library(kernlab)\n",
    "library(e1071)\n",
    "library(data.table)\n",
    "library(dplyr)\n",
    "\n",
    "full_data <- read.table(\"credit_card_data-headers.txt\", header = TRUE)\n",
    "different_cost_values <- c(0.001,0.01,0.1,1,10,100,1000)\n",
    "different_kernel_list <- c(\"vanilladot\", \"rbfdot\", \"anovadot\", \"polydot\")\n",
    "accuracy_value <- c()\n",
    "c_value <- c()\n",
    "kernel_value <- c()\n",
    "weights_value <- c()\n",
    "bias_value <- c()\n",
    "\n",
    "for (i in 1:length(different_kernel_list)){\n",
    "#     print(i)\n",
    "    for (j in 1:length(different_cost_values)){\n",
    "#     print(j)\n",
    "        model <- ksvm(as.matrix(full_data[,1:10]), as.factor(full_data[,11]), \n",
    "                      type= \"C-svc\", kernel = different_kernel_list[i], \n",
    "                      C = different_cost_values[j], scaled=TRUE)\n",
    "#         print(model)\n",
    "        a <- colSums(model@xmatrix[[1]] * model@coef[[1]])\n",
    "#         print(a)\n",
    "        a0 <- model@b\n",
    "#         print(a0)\n",
    "        pred <- predict(model,full_data[,1:10])\n",
    "#         print(pred)\n",
    "        accur <- sum(pred == full_data[,11]) / nrow(full_data)\n",
    "#         print(max(accur))                                \n",
    "        accuracy_value <- c(accuracy_value,accur)\n",
    "#         print(as.data.frame(accuracy_value))\n",
    "        c_value <- c(c_value, different_cost_values[j])\n",
    "        kernel_value <- c(kernel_value,different_kernel_list[i])\n",
    "        weights_value <- c(weights_value,a)  # the length of weights is 280 and number of unique weight is 10\n",
    "        bias_value <- c(bias_value,a0)\n",
    "    }\n",
    "}\n",
    "\n",
    "weights1 <- as.data.frame(matrix(weights_value, 28, 10, byrow = T))\n",
    "df <- data.frame(kernel_value, c_value, round((accuracy_value*100),3), round(bias_value,3))\n",
    "names(df) <- c(\"Kernel\",\"Cost Value\",\"Accuracy\", \"a0\")\n",
    "df1 <- merge(df, round(weights1, 3), by=0)\n",
    "data_to_drops <- c(\"Row.names\")\n",
    "df2 <- df1[order(df1[\"Accuracy\"], decreasing = TRUE), !(names(df1) %in% data_to_drops)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 (Question 1 and 2) : An Alternate Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reproducing the above KSVM function with a slight twist of considering 70-30 Train-Test Split for the best cost value for each of the above kernel function methods.**\n",
    "\n",
    "**Using the alternate mrthod \"rbfdot\" Kernel has performed extremly well with an accuracy of \"83.673\" and C(lambda) of 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Equation based on the maximum accuracy produced by the model\n",
    "\n",
    "    y = (-0.06 x A1) + (0.819 x A2) + (3.748 x A3) + (13.569 x A8) + (26.005 x A9) + (-2.745 x A10) + (9.356 x A11) +         (-2.473 x A12) + (-10.654 x A14) + (16.728 x A15) - 0.459\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### My understanding of the output\n",
    "\n",
    "Although the accuracy is less compared to the output of the previous method I'm happy that I've overcome the **Overfitting** issue by splitting the data into Train and Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Used the following links to understand train-test split using R**\n",
    "\n",
    "    1. https://cran.r-project.org/web/packages/dataPreparation/vignettes/train_test_prep.html\n",
    "    2. https://www.listendata.com/2015/02/splitting-data-into-training-and-test.html\n",
    "    3. https://stackoverflow.com/questions/17200114/how-to-split-data-into-training-testing-sets-using-sample-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Kernel</th><th scope=col>Cost Value</th><th scope=col>Accuracy</th><th scope=col>a0</th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>rbfdot    </td><td>   1.000  </td><td>83.673    </td><td>-0.459    </td><td> -0.060   </td><td>   0.819  </td><td>  3.748   </td><td> 13.569   </td><td> 26.005   </td><td> -2.745   </td><td> 9.356    </td><td> -2.473   </td><td> -10.654  </td><td>16.728    </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>anovadot  </td><td>   0.100  </td><td>83.673    </td><td>-0.070    </td><td> -0.003   </td><td>  -0.206  </td><td> -0.084   </td><td>  0.090   </td><td>  2.039   </td><td> -0.011   </td><td> 0.020    </td><td>  0.000   </td><td>   0.089  </td><td> 1.895    </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>anovadot  </td><td>   1.000  </td><td>83.673    </td><td>-0.851    </td><td> -0.044   </td><td>  -2.101  </td><td> -0.718   </td><td>  0.986   </td><td>  2.182   </td><td> -0.194   </td><td>-0.322    </td><td>  0.010   </td><td>   1.407  </td><td>18.397    </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>vanilladot</td><td>   0.010  </td><td>83.673    </td><td>-0.083    </td><td> -0.002   </td><td>  -0.006  </td><td>  0.011   </td><td>  0.035   </td><td>  0.962   </td><td> -0.011   </td><td> 0.036    </td><td> -0.002   </td><td>  -0.005  </td><td> 0.105    </td></tr>\n",
       "\t<tr><th scope=row>16</th><td>polydot   </td><td>   0.010  </td><td>83.673    </td><td>-0.083    </td><td> -0.002   </td><td>  -0.006  </td><td>  0.011   </td><td>  0.035   </td><td>  0.962   </td><td> -0.011   </td><td> 0.036    </td><td> -0.002   </td><td>  -0.005  </td><td> 0.105    </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>polydot   </td><td>   0.100  </td><td>83.673    </td><td>-0.089    </td><td> -0.002   </td><td>  -0.002  </td><td> -0.001   </td><td>  0.007   </td><td>  1.003   </td><td> -0.003   </td><td> 0.002    </td><td> -0.001   </td><td>   0.000  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>18</th><td>polydot   </td><td>   1.000  </td><td>83.673    </td><td>-0.088    </td><td> -0.002   </td><td>  -0.003  </td><td> -0.002   </td><td>  0.010   </td><td>  1.006   </td><td> -0.002   </td><td> 0.002    </td><td> -0.002   </td><td>   0.000  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>polydot   </td><td>  10.000  </td><td>83.673    </td><td>-0.088    </td><td> -0.002   </td><td>  -0.003  </td><td> -0.001   </td><td>  0.008   </td><td>  1.006   </td><td> -0.002   </td><td> 0.002    </td><td> -0.002   </td><td>  -0.001  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>20</th><td>polydot   </td><td> 100.000  </td><td>83.673    </td><td>-0.087    </td><td> -0.002   </td><td>  -0.003  </td><td> -0.002   </td><td>  0.009   </td><td>  1.007   </td><td> -0.002   </td><td> 0.002    </td><td> -0.002   </td><td>  -0.001  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>polydot   </td><td>1000.000  </td><td>83.673    </td><td>-0.078    </td><td>  0.000   </td><td>   0.000  </td><td>  0.000   </td><td>  0.001   </td><td>  0.998   </td><td> -0.001   </td><td> 0.000    </td><td>  0.000   </td><td>   0.000  </td><td> 0.001    </td></tr>\n",
       "\t<tr><th scope=row>22</th><td>vanilladot</td><td>   0.100  </td><td>83.673    </td><td>-0.089    </td><td> -0.002   </td><td>  -0.002  </td><td> -0.001   </td><td>  0.008   </td><td>  1.003   </td><td> -0.003   </td><td> 0.002    </td><td> -0.001   </td><td>   0.000  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>23</th><td>vanilladot</td><td>   1.000  </td><td>83.673    </td><td>-0.087    </td><td> -0.003   </td><td>  -0.003  </td><td> -0.001   </td><td>  0.009   </td><td>  1.006   </td><td> -0.002   </td><td> 0.003    </td><td> -0.002   </td><td>   0.000  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>24</th><td>vanilladot</td><td>  10.000  </td><td>83.673    </td><td>-0.088    </td><td> -0.003   </td><td>  -0.003  </td><td> -0.001   </td><td>  0.008   </td><td>  1.006   </td><td> -0.002   </td><td> 0.002    </td><td> -0.002   </td><td>  -0.001  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>25</th><td>vanilladot</td><td> 100.000  </td><td>83.673    </td><td>-0.088    </td><td> -0.002   </td><td>  -0.003  </td><td> -0.002   </td><td>  0.009   </td><td>  1.006   </td><td> -0.002   </td><td> 0.002    </td><td> -0.002   </td><td>  -0.001  </td><td> 0.107    </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>vanilladot</td><td>1000.000  </td><td>83.673    </td><td>-0.078    </td><td>  0.000   </td><td>   0.000  </td><td>  0.001   </td><td>  0.000   </td><td>  0.999   </td><td>  0.000   </td><td> 0.000    </td><td>  0.000   </td><td>   0.000  </td><td> 0.001    </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>rbfdot    </td><td>   0.100  </td><td>83.163    </td><td>-0.495    </td><td>  0.247   </td><td>   2.651  </td><td>  3.040   </td><td>  7.128   </td><td> 15.311   </td><td> -3.572   </td><td> 5.823    </td><td> -0.530   </td><td>  -1.762  </td><td> 5.156    </td></tr>\n",
       "\t<tr><th scope=row>11</th><td>anovadot  </td><td>  10.000  </td><td>81.633    </td><td>-1.511    </td><td>  0.048   </td><td>  -6.671  </td><td> -9.844   </td><td>  2.710   </td><td>  2.872   </td><td> -0.803   </td><td> 0.373    </td><td> -0.013   </td><td>   5.759  </td><td>35.886    </td></tr>\n",
       "\t<tr><th scope=row>13</th><td>anovadot  </td><td> 100.000  </td><td>81.633    </td><td>-2.651    </td><td>  0.166   </td><td> -14.771  </td><td>-37.191   </td><td>  3.119   </td><td>  2.819   </td><td> -1.233   </td><td> 1.737    </td><td>  0.074   </td><td>   3.647  </td><td>56.462    </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>rbfdot    </td><td>1000.000  </td><td>81.122    </td><td>-1.202    </td><td>-31.999   </td><td>-102.940  </td><td>-49.720   </td><td> 72.072   </td><td>122.958   </td><td>-37.460   </td><td>46.517    </td><td>-58.618   </td><td>-101.104  </td><td>34.890    </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>rbfdot    </td><td> 100.000  </td><td>80.612    </td><td>-0.374    </td><td>-14.415   </td><td> -37.871  </td><td> 10.368   </td><td> 65.025   </td><td> 54.506   </td><td>-23.000   </td><td>18.287    </td><td>-26.748   </td><td> -56.384  </td><td>33.791    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>rbfdot    </td><td>  10.000  </td><td>80.102    </td><td>-0.485    </td><td> -5.983   </td><td>  -9.964  </td><td>  7.596   </td><td> 22.676   </td><td> 27.682   </td><td> -5.694   </td><td> 3.607    </td><td> -9.688   </td><td> -18.861  </td><td>19.022    </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>anovadot  </td><td>1000.000  </td><td>80.102    </td><td>-4.691    </td><td>  0.151   </td><td> -36.112  </td><td>-60.090   </td><td>-10.436   </td><td>  3.199   </td><td> -1.785   </td><td>-2.353    </td><td>  0.057   </td><td>  -2.509  </td><td>17.503    </td></tr>\n",
       "\t<tr><th scope=row>1</th><td>vanilladot</td><td>   0.001  </td><td>76.531    </td><td> 0.336    </td><td> -0.002   </td><td>   0.038  </td><td>  0.061   </td><td>  0.111   </td><td>  0.283   </td><td> -0.155   </td><td> 0.159    </td><td> -0.015   </td><td>  -0.023  </td><td> 0.064    </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>polydot   </td><td>   0.001  </td><td>76.531    </td><td> 0.336    </td><td> -0.002   </td><td>   0.038  </td><td>  0.061   </td><td>  0.111   </td><td>  0.283   </td><td> -0.155   </td><td> 0.159    </td><td> -0.015   </td><td>  -0.023  </td><td> 0.064    </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>anovadot  </td><td>   0.001  </td><td>54.592    </td><td> 0.541    </td><td> -0.004   </td><td>   0.059  </td><td>  0.086   </td><td>  0.149   </td><td>  0.299   </td><td> -0.171   </td><td> 0.187    </td><td> -0.016   </td><td>  -0.032  </td><td> 0.069    </td></tr>\n",
       "\t<tr><th scope=row>27</th><td>rbfdot    </td><td>   0.001  </td><td>54.592    </td><td> 0.952    </td><td>  0.017   </td><td>   0.066  </td><td>  0.089   </td><td>  0.152   </td><td>  0.299   </td><td> -0.171   </td><td> 0.187    </td><td> -0.022   </td><td>  -0.039  </td><td> 0.069    </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>rbfdot    </td><td>   0.010  </td><td>54.592    </td><td> 0.512    </td><td>  0.177   </td><td>   0.674  </td><td>  0.895   </td><td>  1.519   </td><td>  2.986   </td><td> -1.709   </td><td> 1.872    </td><td> -0.217   </td><td>  -0.384  </td><td> 0.694    </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>anovadot  </td><td>   0.010  </td><td>45.408    </td><td>-0.235    </td><td> -0.014   </td><td>   0.023  </td><td>  0.082   </td><td>  0.342   </td><td>  1.511   </td><td> -0.230   </td><td> 0.344    </td><td> -0.038   </td><td>  -0.091  </td><td> 0.459    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & Kernel & Cost Value & Accuracy & a0 & V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10\\\\\n",
       "\\hline\n",
       "\t3 & rbfdot     &    1.000   & 83.673     & -0.459     &  -0.060    &    0.819   &   3.748    &  13.569    &  26.005    &  -2.745    &  9.356     &  -2.473    &  -10.654   & 16.728    \\\\\n",
       "\t9 & anovadot   &    0.100   & 83.673     & -0.070     &  -0.003    &   -0.206   &  -0.084    &   0.090    &   2.039    &  -0.011    &  0.020     &   0.000    &    0.089   &  1.895    \\\\\n",
       "\t10 & anovadot   &    1.000   & 83.673     & -0.851     &  -0.044    &   -2.101   &  -0.718    &   0.986    &   2.182    &  -0.194    & -0.322     &   0.010    &    1.407   & 18.397    \\\\\n",
       "\t12 & vanilladot &    0.010   & 83.673     & -0.083     &  -0.002    &   -0.006   &   0.011    &   0.035    &   0.962    &  -0.011    &  0.036     &  -0.002    &   -0.005   &  0.105    \\\\\n",
       "\t16 & polydot    &    0.010   & 83.673     & -0.083     &  -0.002    &   -0.006   &   0.011    &   0.035    &   0.962    &  -0.011    &  0.036     &  -0.002    &   -0.005   &  0.105    \\\\\n",
       "\t17 & polydot    &    0.100   & 83.673     & -0.089     &  -0.002    &   -0.002   &  -0.001    &   0.007    &   1.003    &  -0.003    &  0.002     &  -0.001    &    0.000   &  0.107    \\\\\n",
       "\t18 & polydot    &    1.000   & 83.673     & -0.088     &  -0.002    &   -0.003   &  -0.002    &   0.010    &   1.006    &  -0.002    &  0.002     &  -0.002    &    0.000   &  0.107    \\\\\n",
       "\t19 & polydot    &   10.000   & 83.673     & -0.088     &  -0.002    &   -0.003   &  -0.001    &   0.008    &   1.006    &  -0.002    &  0.002     &  -0.002    &   -0.001   &  0.107    \\\\\n",
       "\t20 & polydot    &  100.000   & 83.673     & -0.087     &  -0.002    &   -0.003   &  -0.002    &   0.009    &   1.007    &  -0.002    &  0.002     &  -0.002    &   -0.001   &  0.107    \\\\\n",
       "\t21 & polydot    & 1000.000   & 83.673     & -0.078     &   0.000    &    0.000   &   0.000    &   0.001    &   0.998    &  -0.001    &  0.000     &   0.000    &    0.000   &  0.001    \\\\\n",
       "\t22 & vanilladot &    0.100   & 83.673     & -0.089     &  -0.002    &   -0.002   &  -0.001    &   0.008    &   1.003    &  -0.003    &  0.002     &  -0.001    &    0.000   &  0.107    \\\\\n",
       "\t23 & vanilladot &    1.000   & 83.673     & -0.087     &  -0.003    &   -0.003   &  -0.001    &   0.009    &   1.006    &  -0.002    &  0.003     &  -0.002    &    0.000   &  0.107    \\\\\n",
       "\t24 & vanilladot &   10.000   & 83.673     & -0.088     &  -0.003    &   -0.003   &  -0.001    &   0.008    &   1.006    &  -0.002    &  0.002     &  -0.002    &   -0.001   &  0.107    \\\\\n",
       "\t25 & vanilladot &  100.000   & 83.673     & -0.088     &  -0.002    &   -0.003   &  -0.002    &   0.009    &   1.006    &  -0.002    &  0.002     &  -0.002    &   -0.001   &  0.107    \\\\\n",
       "\t26 & vanilladot & 1000.000   & 83.673     & -0.078     &   0.000    &    0.000   &   0.001    &   0.000    &   0.999    &   0.000    &  0.000     &   0.000    &    0.000   &  0.001    \\\\\n",
       "\t2 & rbfdot     &    0.100   & 83.163     & -0.495     &   0.247    &    2.651   &   3.040    &   7.128    &  15.311    &  -3.572    &  5.823     &  -0.530    &   -1.762   &  5.156    \\\\\n",
       "\t11 & anovadot   &   10.000   & 81.633     & -1.511     &   0.048    &   -6.671   &  -9.844    &   2.710    &   2.872    &  -0.803    &  0.373     &  -0.013    &    5.759   & 35.886    \\\\\n",
       "\t13 & anovadot   &  100.000   & 81.633     & -2.651     &   0.166    &  -14.771   & -37.191    &   3.119    &   2.819    &  -1.233    &  1.737     &   0.074    &    3.647   & 56.462    \\\\\n",
       "\t6 & rbfdot     & 1000.000   & 81.122     & -1.202     & -31.999    & -102.940   & -49.720    &  72.072    & 122.958    & -37.460    & 46.517     & -58.618    & -101.104   & 34.890    \\\\\n",
       "\t5 & rbfdot     &  100.000   & 80.612     & -0.374     & -14.415    &  -37.871   &  10.368    &  65.025    &  54.506    & -23.000    & 18.287     & -26.748    &  -56.384   & 33.791    \\\\\n",
       "\t4 & rbfdot     &   10.000   & 80.102     & -0.485     &  -5.983    &   -9.964   &   7.596    &  22.676    &  27.682    &  -5.694    &  3.607     &  -9.688    &  -18.861   & 19.022    \\\\\n",
       "\t14 & anovadot   & 1000.000   & 80.102     & -4.691     &   0.151    &  -36.112   & -60.090    & -10.436    &   3.199    &  -1.785    & -2.353     &   0.057    &   -2.509   & 17.503    \\\\\n",
       "\t1 & vanilladot &    0.001   & 76.531     &  0.336     &  -0.002    &    0.038   &   0.061    &   0.111    &   0.283    &  -0.155    &  0.159     &  -0.015    &   -0.023   &  0.064    \\\\\n",
       "\t15 & polydot    &    0.001   & 76.531     &  0.336     &  -0.002    &    0.038   &   0.061    &   0.111    &   0.283    &  -0.155    &  0.159     &  -0.015    &   -0.023   &  0.064    \\\\\n",
       "\t7 & anovadot   &    0.001   & 54.592     &  0.541     &  -0.004    &    0.059   &   0.086    &   0.149    &   0.299    &  -0.171    &  0.187     &  -0.016    &   -0.032   &  0.069    \\\\\n",
       "\t27 & rbfdot     &    0.001   & 54.592     &  0.952     &   0.017    &    0.066   &   0.089    &   0.152    &   0.299    &  -0.171    &  0.187     &  -0.022    &   -0.039   &  0.069    \\\\\n",
       "\t28 & rbfdot     &    0.010   & 54.592     &  0.512     &   0.177    &    0.674   &   0.895    &   1.519    &   2.986    &  -1.709    &  1.872     &  -0.217    &   -0.384   &  0.694    \\\\\n",
       "\t8 & anovadot   &    0.010   & 45.408     & -0.235     &  -0.014    &    0.023   &   0.082    &   0.342    &   1.511    &  -0.230    &  0.344     &  -0.038    &   -0.091   &  0.459    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Kernel | Cost Value | Accuracy | a0 | V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3 | rbfdot     |    1.000   | 83.673     | -0.459     |  -0.060    |    0.819   |   3.748    |  13.569    |  26.005    |  -2.745    |  9.356     |  -2.473    |  -10.654   | 16.728     |\n",
       "| 9 | anovadot   |    0.100   | 83.673     | -0.070     |  -0.003    |   -0.206   |  -0.084    |   0.090    |   2.039    |  -0.011    |  0.020     |   0.000    |    0.089   |  1.895     |\n",
       "| 10 | anovadot   |    1.000   | 83.673     | -0.851     |  -0.044    |   -2.101   |  -0.718    |   0.986    |   2.182    |  -0.194    | -0.322     |   0.010    |    1.407   | 18.397     |\n",
       "| 12 | vanilladot |    0.010   | 83.673     | -0.083     |  -0.002    |   -0.006   |   0.011    |   0.035    |   0.962    |  -0.011    |  0.036     |  -0.002    |   -0.005   |  0.105     |\n",
       "| 16 | polydot    |    0.010   | 83.673     | -0.083     |  -0.002    |   -0.006   |   0.011    |   0.035    |   0.962    |  -0.011    |  0.036     |  -0.002    |   -0.005   |  0.105     |\n",
       "| 17 | polydot    |    0.100   | 83.673     | -0.089     |  -0.002    |   -0.002   |  -0.001    |   0.007    |   1.003    |  -0.003    |  0.002     |  -0.001    |    0.000   |  0.107     |\n",
       "| 18 | polydot    |    1.000   | 83.673     | -0.088     |  -0.002    |   -0.003   |  -0.002    |   0.010    |   1.006    |  -0.002    |  0.002     |  -0.002    |    0.000   |  0.107     |\n",
       "| 19 | polydot    |   10.000   | 83.673     | -0.088     |  -0.002    |   -0.003   |  -0.001    |   0.008    |   1.006    |  -0.002    |  0.002     |  -0.002    |   -0.001   |  0.107     |\n",
       "| 20 | polydot    |  100.000   | 83.673     | -0.087     |  -0.002    |   -0.003   |  -0.002    |   0.009    |   1.007    |  -0.002    |  0.002     |  -0.002    |   -0.001   |  0.107     |\n",
       "| 21 | polydot    | 1000.000   | 83.673     | -0.078     |   0.000    |    0.000   |   0.000    |   0.001    |   0.998    |  -0.001    |  0.000     |   0.000    |    0.000   |  0.001     |\n",
       "| 22 | vanilladot |    0.100   | 83.673     | -0.089     |  -0.002    |   -0.002   |  -0.001    |   0.008    |   1.003    |  -0.003    |  0.002     |  -0.001    |    0.000   |  0.107     |\n",
       "| 23 | vanilladot |    1.000   | 83.673     | -0.087     |  -0.003    |   -0.003   |  -0.001    |   0.009    |   1.006    |  -0.002    |  0.003     |  -0.002    |    0.000   |  0.107     |\n",
       "| 24 | vanilladot |   10.000   | 83.673     | -0.088     |  -0.003    |   -0.003   |  -0.001    |   0.008    |   1.006    |  -0.002    |  0.002     |  -0.002    |   -0.001   |  0.107     |\n",
       "| 25 | vanilladot |  100.000   | 83.673     | -0.088     |  -0.002    |   -0.003   |  -0.002    |   0.009    |   1.006    |  -0.002    |  0.002     |  -0.002    |   -0.001   |  0.107     |\n",
       "| 26 | vanilladot | 1000.000   | 83.673     | -0.078     |   0.000    |    0.000   |   0.001    |   0.000    |   0.999    |   0.000    |  0.000     |   0.000    |    0.000   |  0.001     |\n",
       "| 2 | rbfdot     |    0.100   | 83.163     | -0.495     |   0.247    |    2.651   |   3.040    |   7.128    |  15.311    |  -3.572    |  5.823     |  -0.530    |   -1.762   |  5.156     |\n",
       "| 11 | anovadot   |   10.000   | 81.633     | -1.511     |   0.048    |   -6.671   |  -9.844    |   2.710    |   2.872    |  -0.803    |  0.373     |  -0.013    |    5.759   | 35.886     |\n",
       "| 13 | anovadot   |  100.000   | 81.633     | -2.651     |   0.166    |  -14.771   | -37.191    |   3.119    |   2.819    |  -1.233    |  1.737     |   0.074    |    3.647   | 56.462     |\n",
       "| 6 | rbfdot     | 1000.000   | 81.122     | -1.202     | -31.999    | -102.940   | -49.720    |  72.072    | 122.958    | -37.460    | 46.517     | -58.618    | -101.104   | 34.890     |\n",
       "| 5 | rbfdot     |  100.000   | 80.612     | -0.374     | -14.415    |  -37.871   |  10.368    |  65.025    |  54.506    | -23.000    | 18.287     | -26.748    |  -56.384   | 33.791     |\n",
       "| 4 | rbfdot     |   10.000   | 80.102     | -0.485     |  -5.983    |   -9.964   |   7.596    |  22.676    |  27.682    |  -5.694    |  3.607     |  -9.688    |  -18.861   | 19.022     |\n",
       "| 14 | anovadot   | 1000.000   | 80.102     | -4.691     |   0.151    |  -36.112   | -60.090    | -10.436    |   3.199    |  -1.785    | -2.353     |   0.057    |   -2.509   | 17.503     |\n",
       "| 1 | vanilladot |    0.001   | 76.531     |  0.336     |  -0.002    |    0.038   |   0.061    |   0.111    |   0.283    |  -0.155    |  0.159     |  -0.015    |   -0.023   |  0.064     |\n",
       "| 15 | polydot    |    0.001   | 76.531     |  0.336     |  -0.002    |    0.038   |   0.061    |   0.111    |   0.283    |  -0.155    |  0.159     |  -0.015    |   -0.023   |  0.064     |\n",
       "| 7 | anovadot   |    0.001   | 54.592     |  0.541     |  -0.004    |    0.059   |   0.086    |   0.149    |   0.299    |  -0.171    |  0.187     |  -0.016    |   -0.032   |  0.069     |\n",
       "| 27 | rbfdot     |    0.001   | 54.592     |  0.952     |   0.017    |    0.066   |   0.089    |   0.152    |   0.299    |  -0.171    |  0.187     |  -0.022    |   -0.039   |  0.069     |\n",
       "| 28 | rbfdot     |    0.010   | 54.592     |  0.512     |   0.177    |    0.674   |   0.895    |   1.519    |   2.986    |  -1.709    |  1.872     |  -0.217    |   -0.384   |  0.694     |\n",
       "| 8 | anovadot   |    0.010   | 45.408     | -0.235     |  -0.014    |    0.023   |   0.082    |   0.342    |   1.511    |  -0.230    |  0.344     |  -0.038    |   -0.091   |  0.459     |\n",
       "\n"
      ],
      "text/plain": [
       "   Kernel     Cost Value Accuracy a0     V1      V2       V3      V4     \n",
       "3  rbfdot        1.000   83.673   -0.459  -0.060    0.819   3.748  13.569\n",
       "9  anovadot      0.100   83.673   -0.070  -0.003   -0.206  -0.084   0.090\n",
       "10 anovadot      1.000   83.673   -0.851  -0.044   -2.101  -0.718   0.986\n",
       "12 vanilladot    0.010   83.673   -0.083  -0.002   -0.006   0.011   0.035\n",
       "16 polydot       0.010   83.673   -0.083  -0.002   -0.006   0.011   0.035\n",
       "17 polydot       0.100   83.673   -0.089  -0.002   -0.002  -0.001   0.007\n",
       "18 polydot       1.000   83.673   -0.088  -0.002   -0.003  -0.002   0.010\n",
       "19 polydot      10.000   83.673   -0.088  -0.002   -0.003  -0.001   0.008\n",
       "20 polydot     100.000   83.673   -0.087  -0.002   -0.003  -0.002   0.009\n",
       "21 polydot    1000.000   83.673   -0.078   0.000    0.000   0.000   0.001\n",
       "22 vanilladot    0.100   83.673   -0.089  -0.002   -0.002  -0.001   0.008\n",
       "23 vanilladot    1.000   83.673   -0.087  -0.003   -0.003  -0.001   0.009\n",
       "24 vanilladot   10.000   83.673   -0.088  -0.003   -0.003  -0.001   0.008\n",
       "25 vanilladot  100.000   83.673   -0.088  -0.002   -0.003  -0.002   0.009\n",
       "26 vanilladot 1000.000   83.673   -0.078   0.000    0.000   0.001   0.000\n",
       "2  rbfdot        0.100   83.163   -0.495   0.247    2.651   3.040   7.128\n",
       "11 anovadot     10.000   81.633   -1.511   0.048   -6.671  -9.844   2.710\n",
       "13 anovadot    100.000   81.633   -2.651   0.166  -14.771 -37.191   3.119\n",
       "6  rbfdot     1000.000   81.122   -1.202 -31.999 -102.940 -49.720  72.072\n",
       "5  rbfdot      100.000   80.612   -0.374 -14.415  -37.871  10.368  65.025\n",
       "4  rbfdot       10.000   80.102   -0.485  -5.983   -9.964   7.596  22.676\n",
       "14 anovadot   1000.000   80.102   -4.691   0.151  -36.112 -60.090 -10.436\n",
       "1  vanilladot    0.001   76.531    0.336  -0.002    0.038   0.061   0.111\n",
       "15 polydot       0.001   76.531    0.336  -0.002    0.038   0.061   0.111\n",
       "7  anovadot      0.001   54.592    0.541  -0.004    0.059   0.086   0.149\n",
       "27 rbfdot        0.001   54.592    0.952   0.017    0.066   0.089   0.152\n",
       "28 rbfdot        0.010   54.592    0.512   0.177    0.674   0.895   1.519\n",
       "8  anovadot      0.010   45.408   -0.235  -0.014    0.023   0.082   0.342\n",
       "   V5      V6      V7     V8      V9       V10   \n",
       "3   26.005  -2.745  9.356  -2.473  -10.654 16.728\n",
       "9    2.039  -0.011  0.020   0.000    0.089  1.895\n",
       "10   2.182  -0.194 -0.322   0.010    1.407 18.397\n",
       "12   0.962  -0.011  0.036  -0.002   -0.005  0.105\n",
       "16   0.962  -0.011  0.036  -0.002   -0.005  0.105\n",
       "17   1.003  -0.003  0.002  -0.001    0.000  0.107\n",
       "18   1.006  -0.002  0.002  -0.002    0.000  0.107\n",
       "19   1.006  -0.002  0.002  -0.002   -0.001  0.107\n",
       "20   1.007  -0.002  0.002  -0.002   -0.001  0.107\n",
       "21   0.998  -0.001  0.000   0.000    0.000  0.001\n",
       "22   1.003  -0.003  0.002  -0.001    0.000  0.107\n",
       "23   1.006  -0.002  0.003  -0.002    0.000  0.107\n",
       "24   1.006  -0.002  0.002  -0.002   -0.001  0.107\n",
       "25   1.006  -0.002  0.002  -0.002   -0.001  0.107\n",
       "26   0.999   0.000  0.000   0.000    0.000  0.001\n",
       "2   15.311  -3.572  5.823  -0.530   -1.762  5.156\n",
       "11   2.872  -0.803  0.373  -0.013    5.759 35.886\n",
       "13   2.819  -1.233  1.737   0.074    3.647 56.462\n",
       "6  122.958 -37.460 46.517 -58.618 -101.104 34.890\n",
       "5   54.506 -23.000 18.287 -26.748  -56.384 33.791\n",
       "4   27.682  -5.694  3.607  -9.688  -18.861 19.022\n",
       "14   3.199  -1.785 -2.353   0.057   -2.509 17.503\n",
       "1    0.283  -0.155  0.159  -0.015   -0.023  0.064\n",
       "15   0.283  -0.155  0.159  -0.015   -0.023  0.064\n",
       "7    0.299  -0.171  0.187  -0.016   -0.032  0.069\n",
       "27   0.299  -0.171  0.187  -0.022   -0.039  0.069\n",
       "28   2.986  -1.709  1.872  -0.217   -0.384  0.694\n",
       "8    1.511  -0.230  0.344  -0.038   -0.091  0.459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the needed packages\n",
    "options(scipen = 999)\n",
    "library(kernlab)\n",
    "library(e1071)\n",
    "library(data.table)\n",
    "library(dplyr)\n",
    "library(caTools)\n",
    "set.seed(101)\n",
    "\n",
    "full_data <- read.table(\"credit_card_data-headers.txt\", header = TRUE)\n",
    "\n",
    "sample = sample.split(full_data$R1, SplitRatio = 0.70)\n",
    "X_data_train <- subset(data[,1:10], sample == TRUE)\n",
    "y_data_train <- subset(data[,11], sample == TRUE)\n",
    "X_data_test <- subset(data[,1:10], sample == FALSE)\n",
    "y_data_test <- subset(data[,11], sample == FALSE)\n",
    "\n",
    "different_cost_values <- c(0.001,0.01,0.1,1,10,100,1000)\n",
    "different_kernel_list <- c(\"vanilladot\", \"rbfdot\", \"anovadot\", \"polydot\")\n",
    "accuracy_value <- c()\n",
    "c_value <- c()\n",
    "kernel_value <- c()\n",
    "weights_value <- c()\n",
    "bias_value <- c()\n",
    "\n",
    "for (i in 1:length(different_kernel_list)){\n",
    "#     print(i)\n",
    "    for (j in 1:length(different_cost_values)){\n",
    "#     print(j)\n",
    "        model <- ksvm(as.matrix(X_data_train), as.factor(y_data_train), \n",
    "                      type= \"C-svc\", kernel = different_kernel_list[i], \n",
    "                      C = different_cost_values[j], scaled=TRUE)\n",
    "#         print(model)\n",
    "        a <- colSums(model@xmatrix[[1]] * model@coef[[1]])\n",
    "#         print(a)\n",
    "        a0 <- model@b\n",
    "#         print(a0)\n",
    "        pred <- predict(model,X_data_test)\n",
    "#         print(pred)\n",
    "        accur <- sum(pred == y_data_test) / length(y_data_test)\n",
    "#         print(max(accur))                                \n",
    "        accuracy_value <- c(accuracy_value,accur)\n",
    "#         print(as.data.frame(accuracy_value))\n",
    "        c_value <- c(c_value, different_cost_values[j])\n",
    "        kernel_value <- c(kernel_value,different_kernel_list[i])\n",
    "        weights_value <- c(weights_value,a) # the length of weights is 280 and number of unique weight is 10\n",
    "        bias_value <- c(bias_value,a0)\n",
    "    }\n",
    "}\n",
    "\n",
    "weights1 <- as.data.frame(matrix(weights_value, 28, 10, byrow = T))\n",
    "df <- data.frame(kernel_value, c_value, round((accuracy_value*100),3), round(bias_value,3))\n",
    "names(df) <- c(\"Kernel\",\"Cost Value\",\"Accuracy\", \"a0\")\n",
    "df1 <- merge(df, round(weights1, 3), by=0)\n",
    "data_to_drops <- c(\"Row.names\")\n",
    "df2 <- df1[order(df1[\"Accuracy\"], decreasing = TRUE), !(names(df1) %in% data_to_drops)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 (Question 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I'll approach the same usecase but this time I'll be using K Nearest Neighbor(KNN)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stepwise explanation to the problem approach:\n",
    "\n",
    "For this problem, I've used different k values to check which k value suites. This is passes on different kernel function. The knn method looks at all the data except for the i-th row of data. I've looped through different values of k to perform the same.\n",
    "For each kernel and each k value, I'm appending the model accuracy, k value and name of the kernel to the empty vectors that I've defined. After this step, I am joining these vectors to a dataframe and sorted (descending) by accuracy.\n",
    "\n",
    "\n",
    "**Using this approach, 12 and 15 seem to be good values of k, and the model accuracy for both the values of k is 85.32110 %. \n",
    "Since, we are using KNN I would prefer to choose k = 15 an odd number for k.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Kernel</th><th scope=col>K Value</th><th scope=col>Model Accuracy</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>517</th><td>optimal    </td><td>12         </td><td>85.32110   </td></tr>\n",
       "\t<tr><th scope=row>520</th><td>optimal    </td><td>15         </td><td>85.32110   </td></tr>\n",
       "\t<tr><th scope=row>111</th><td>triangular </td><td>10         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>510</th><td>optimal    </td><td> 5         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>516</th><td>optimal    </td><td>11         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>518</th><td>optimal    </td><td>13         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>519</th><td>optimal    </td><td>14         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>521</th><td>optimal    </td><td>16         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>522</th><td>optimal    </td><td>17         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>523</th><td>optimal    </td><td>18         </td><td>85.16820   </td></tr>\n",
       "\t<tr><th scope=row>22</th><td>rectangular</td><td>22         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>44</th><td>rectangular</td><td>44         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>112</th><td>triangular </td><td>11         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>113</th><td>triangular </td><td>12         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>115</th><td>triangular </td><td>14         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>244</th><td>inv        </td><td>42         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>311</th><td>gaussian   </td><td> 8         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>426</th><td>rank       </td><td>22         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>448</th><td>rank       </td><td>44         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>515</th><td>optimal    </td><td>10         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>524</th><td>optimal    </td><td>19         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>525</th><td>optimal    </td><td>20         </td><td>85.01529   </td></tr>\n",
       "\t<tr><th scope=row>48</th><td>rectangular</td><td>48         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>114</th><td>triangular </td><td>13         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>116</th><td>triangular </td><td>15         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>117</th><td>triangular </td><td>16         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>118</th><td>triangular </td><td>17         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>208</th><td>inv        </td><td> 6         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>245</th><td>inv        </td><td>43         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>452</th><td>rank       </td><td>48         </td><td>84.86239   </td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>331</th><td>gaussian   </td><td>28         </td><td>82.72171   </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>rectangular</td><td> 4         </td><td>82.56881   </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>rectangular</td><td>15         </td><td>82.56881   </td></tr>\n",
       "\t<tr><th scope=row>329</th><td>gaussian   </td><td>26         </td><td>82.56881   </td></tr>\n",
       "\t<tr><th scope=row>408</th><td>rank       </td><td> 4         </td><td>82.56881   </td></tr>\n",
       "\t<tr><th scope=row>419</th><td>rank       </td><td>15         </td><td>82.56881   </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>rectangular</td><td> 3         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>rectangular</td><td>17         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>rectangular</td><td>19         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>205</th><td>inv        </td><td> 3         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>306</th><td>gaussian   </td><td> 3         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>407</th><td>rank       </td><td> 3         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>421</th><td>rank       </td><td>17         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>423</th><td>rank       </td><td>19         </td><td>82.26300   </td></tr>\n",
       "\t<tr><th scope=row>105</th><td>triangular </td><td> 4         </td><td>81.95719   </td></tr>\n",
       "\t<tr><th scope=row>1</th><td>rectangular</td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>102</th><td>triangular </td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>103</th><td>triangular </td><td> 2         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>203</th><td>inv        </td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>204</th><td>inv        </td><td> 2         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>304</th><td>gaussian   </td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>305</th><td>gaussian   </td><td> 2         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>405</th><td>rank       </td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>506</th><td>optimal    </td><td> 1         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>507</th><td>optimal    </td><td> 2         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>508</th><td>optimal    </td><td> 3         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>509</th><td>optimal    </td><td> 4         </td><td>81.49847   </td></tr>\n",
       "\t<tr><th scope=row>104</th><td>triangular </td><td> 3         </td><td>80.88685   </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>rectangular</td><td> 2         </td><td>78.59327   </td></tr>\n",
       "\t<tr><th scope=row>406</th><td>rank       </td><td> 2         </td><td>78.59327   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & Kernel & K Value & Model Accuracy\\\\\n",
       "\\hline\n",
       "\t517 & optimal     & 12          & 85.32110   \\\\\n",
       "\t520 & optimal     & 15          & 85.32110   \\\\\n",
       "\t111 & triangular  & 10          & 85.16820   \\\\\n",
       "\t510 & optimal     &  5          & 85.16820   \\\\\n",
       "\t516 & optimal     & 11          & 85.16820   \\\\\n",
       "\t518 & optimal     & 13          & 85.16820   \\\\\n",
       "\t519 & optimal     & 14          & 85.16820   \\\\\n",
       "\t521 & optimal     & 16          & 85.16820   \\\\\n",
       "\t522 & optimal     & 17          & 85.16820   \\\\\n",
       "\t523 & optimal     & 18          & 85.16820   \\\\\n",
       "\t22 & rectangular & 22          & 85.01529   \\\\\n",
       "\t44 & rectangular & 44          & 85.01529   \\\\\n",
       "\t112 & triangular  & 11          & 85.01529   \\\\\n",
       "\t113 & triangular  & 12          & 85.01529   \\\\\n",
       "\t115 & triangular  & 14          & 85.01529   \\\\\n",
       "\t244 & inv         & 42          & 85.01529   \\\\\n",
       "\t311 & gaussian    &  8          & 85.01529   \\\\\n",
       "\t426 & rank        & 22          & 85.01529   \\\\\n",
       "\t448 & rank        & 44          & 85.01529   \\\\\n",
       "\t515 & optimal     & 10          & 85.01529   \\\\\n",
       "\t524 & optimal     & 19          & 85.01529   \\\\\n",
       "\t525 & optimal     & 20          & 85.01529   \\\\\n",
       "\t48 & rectangular & 48          & 84.86239   \\\\\n",
       "\t114 & triangular  & 13          & 84.86239   \\\\\n",
       "\t116 & triangular  & 15          & 84.86239   \\\\\n",
       "\t117 & triangular  & 16          & 84.86239   \\\\\n",
       "\t118 & triangular  & 17          & 84.86239   \\\\\n",
       "\t208 & inv         &  6          & 84.86239   \\\\\n",
       "\t245 & inv         & 43          & 84.86239   \\\\\n",
       "\t452 & rank        & 48          & 84.86239   \\\\\n",
       "\t... & ... & ... & ...\\\\\n",
       "\t331 & gaussian    & 28          & 82.72171   \\\\\n",
       "\t4 & rectangular &  4          & 82.56881   \\\\\n",
       "\t15 & rectangular & 15          & 82.56881   \\\\\n",
       "\t329 & gaussian    & 26          & 82.56881   \\\\\n",
       "\t408 & rank        &  4          & 82.56881   \\\\\n",
       "\t419 & rank        & 15          & 82.56881   \\\\\n",
       "\t3 & rectangular &  3          & 82.26300   \\\\\n",
       "\t17 & rectangular & 17          & 82.26300   \\\\\n",
       "\t19 & rectangular & 19          & 82.26300   \\\\\n",
       "\t205 & inv         &  3          & 82.26300   \\\\\n",
       "\t306 & gaussian    &  3          & 82.26300   \\\\\n",
       "\t407 & rank        &  3          & 82.26300   \\\\\n",
       "\t421 & rank        & 17          & 82.26300   \\\\\n",
       "\t423 & rank        & 19          & 82.26300   \\\\\n",
       "\t105 & triangular  &  4          & 81.95719   \\\\\n",
       "\t1 & rectangular &  1          & 81.49847   \\\\\n",
       "\t102 & triangular  &  1          & 81.49847   \\\\\n",
       "\t103 & triangular  &  2          & 81.49847   \\\\\n",
       "\t203 & inv         &  1          & 81.49847   \\\\\n",
       "\t204 & inv         &  2          & 81.49847   \\\\\n",
       "\t304 & gaussian    &  1          & 81.49847   \\\\\n",
       "\t305 & gaussian    &  2          & 81.49847   \\\\\n",
       "\t405 & rank        &  1          & 81.49847   \\\\\n",
       "\t506 & optimal     &  1          & 81.49847   \\\\\n",
       "\t507 & optimal     &  2          & 81.49847   \\\\\n",
       "\t508 & optimal     &  3          & 81.49847   \\\\\n",
       "\t509 & optimal     &  4          & 81.49847   \\\\\n",
       "\t104 & triangular  &  3          & 80.88685   \\\\\n",
       "\t2 & rectangular &  2          & 78.59327   \\\\\n",
       "\t406 & rank        &  2          & 78.59327   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Kernel | K Value | Model Accuracy |\n",
       "|---|---|---|---|\n",
       "| 517 | optimal     | 12          | 85.32110    |\n",
       "| 520 | optimal     | 15          | 85.32110    |\n",
       "| 111 | triangular  | 10          | 85.16820    |\n",
       "| 510 | optimal     |  5          | 85.16820    |\n",
       "| 516 | optimal     | 11          | 85.16820    |\n",
       "| 518 | optimal     | 13          | 85.16820    |\n",
       "| 519 | optimal     | 14          | 85.16820    |\n",
       "| 521 | optimal     | 16          | 85.16820    |\n",
       "| 522 | optimal     | 17          | 85.16820    |\n",
       "| 523 | optimal     | 18          | 85.16820    |\n",
       "| 22 | rectangular | 22          | 85.01529    |\n",
       "| 44 | rectangular | 44          | 85.01529    |\n",
       "| 112 | triangular  | 11          | 85.01529    |\n",
       "| 113 | triangular  | 12          | 85.01529    |\n",
       "| 115 | triangular  | 14          | 85.01529    |\n",
       "| 244 | inv         | 42          | 85.01529    |\n",
       "| 311 | gaussian    |  8          | 85.01529    |\n",
       "| 426 | rank        | 22          | 85.01529    |\n",
       "| 448 | rank        | 44          | 85.01529    |\n",
       "| 515 | optimal     | 10          | 85.01529    |\n",
       "| 524 | optimal     | 19          | 85.01529    |\n",
       "| 525 | optimal     | 20          | 85.01529    |\n",
       "| 48 | rectangular | 48          | 84.86239    |\n",
       "| 114 | triangular  | 13          | 84.86239    |\n",
       "| 116 | triangular  | 15          | 84.86239    |\n",
       "| 117 | triangular  | 16          | 84.86239    |\n",
       "| 118 | triangular  | 17          | 84.86239    |\n",
       "| 208 | inv         |  6          | 84.86239    |\n",
       "| 245 | inv         | 43          | 84.86239    |\n",
       "| 452 | rank        | 48          | 84.86239    |\n",
       "| ... | ... | ... | ... |\n",
       "| 331 | gaussian    | 28          | 82.72171    |\n",
       "| 4 | rectangular |  4          | 82.56881    |\n",
       "| 15 | rectangular | 15          | 82.56881    |\n",
       "| 329 | gaussian    | 26          | 82.56881    |\n",
       "| 408 | rank        |  4          | 82.56881    |\n",
       "| 419 | rank        | 15          | 82.56881    |\n",
       "| 3 | rectangular |  3          | 82.26300    |\n",
       "| 17 | rectangular | 17          | 82.26300    |\n",
       "| 19 | rectangular | 19          | 82.26300    |\n",
       "| 205 | inv         |  3          | 82.26300    |\n",
       "| 306 | gaussian    |  3          | 82.26300    |\n",
       "| 407 | rank        |  3          | 82.26300    |\n",
       "| 421 | rank        | 17          | 82.26300    |\n",
       "| 423 | rank        | 19          | 82.26300    |\n",
       "| 105 | triangular  |  4          | 81.95719    |\n",
       "| 1 | rectangular |  1          | 81.49847    |\n",
       "| 102 | triangular  |  1          | 81.49847    |\n",
       "| 103 | triangular  |  2          | 81.49847    |\n",
       "| 203 | inv         |  1          | 81.49847    |\n",
       "| 204 | inv         |  2          | 81.49847    |\n",
       "| 304 | gaussian    |  1          | 81.49847    |\n",
       "| 305 | gaussian    |  2          | 81.49847    |\n",
       "| 405 | rank        |  1          | 81.49847    |\n",
       "| 506 | optimal     |  1          | 81.49847    |\n",
       "| 507 | optimal     |  2          | 81.49847    |\n",
       "| 508 | optimal     |  3          | 81.49847    |\n",
       "| 509 | optimal     |  4          | 81.49847    |\n",
       "| 104 | triangular  |  3          | 80.88685    |\n",
       "| 2 | rectangular |  2          | 78.59327    |\n",
       "| 406 | rank        |  2          | 78.59327    |\n",
       "\n"
      ],
      "text/plain": [
       "    Kernel      K Value Model Accuracy\n",
       "517 optimal     12      85.32110      \n",
       "520 optimal     15      85.32110      \n",
       "111 triangular  10      85.16820      \n",
       "510 optimal      5      85.16820      \n",
       "516 optimal     11      85.16820      \n",
       "518 optimal     13      85.16820      \n",
       "519 optimal     14      85.16820      \n",
       "521 optimal     16      85.16820      \n",
       "522 optimal     17      85.16820      \n",
       "523 optimal     18      85.16820      \n",
       "22  rectangular 22      85.01529      \n",
       "44  rectangular 44      85.01529      \n",
       "112 triangular  11      85.01529      \n",
       "113 triangular  12      85.01529      \n",
       "115 triangular  14      85.01529      \n",
       "244 inv         42      85.01529      \n",
       "311 gaussian     8      85.01529      \n",
       "426 rank        22      85.01529      \n",
       "448 rank        44      85.01529      \n",
       "515 optimal     10      85.01529      \n",
       "524 optimal     19      85.01529      \n",
       "525 optimal     20      85.01529      \n",
       "48  rectangular 48      84.86239      \n",
       "114 triangular  13      84.86239      \n",
       "116 triangular  15      84.86239      \n",
       "117 triangular  16      84.86239      \n",
       "118 triangular  17      84.86239      \n",
       "208 inv          6      84.86239      \n",
       "245 inv         43      84.86239      \n",
       "452 rank        48      84.86239      \n",
       "... ...         ...     ...           \n",
       "331 gaussian    28      82.72171      \n",
       "4   rectangular  4      82.56881      \n",
       "15  rectangular 15      82.56881      \n",
       "329 gaussian    26      82.56881      \n",
       "408 rank         4      82.56881      \n",
       "419 rank        15      82.56881      \n",
       "3   rectangular  3      82.26300      \n",
       "17  rectangular 17      82.26300      \n",
       "19  rectangular 19      82.26300      \n",
       "205 inv          3      82.26300      \n",
       "306 gaussian     3      82.26300      \n",
       "407 rank         3      82.26300      \n",
       "421 rank        17      82.26300      \n",
       "423 rank        19      82.26300      \n",
       "105 triangular   4      81.95719      \n",
       "1   rectangular  1      81.49847      \n",
       "102 triangular   1      81.49847      \n",
       "103 triangular   2      81.49847      \n",
       "203 inv          1      81.49847      \n",
       "204 inv          2      81.49847      \n",
       "304 gaussian     1      81.49847      \n",
       "305 gaussian     2      81.49847      \n",
       "405 rank         1      81.49847      \n",
       "506 optimal      1      81.49847      \n",
       "507 optimal      2      81.49847      \n",
       "508 optimal      3      81.49847      \n",
       "509 optimal      4      81.49847      \n",
       "104 triangular   3      80.88685      \n",
       "2   rectangular  2      78.59327      \n",
       "406 rank         2      78.59327      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(kernlab)\n",
    "library(kknn)\n",
    "\n",
    "full_data <- read.table(\"credit_card_data-headers.txt\", header = TRUE)\n",
    "\n",
    "k_list <- c(1:101)   # Checking for a correct \"K-value\" so I'm checking for values from 1 to 101\n",
    "different_kernel_list <- c(\"rectangular\" , \"triangular\", \"inv\", \"gaussian\", \"rank\", \"optimal\") # Checking for different function\n",
    "accuracy_value <- c()\n",
    "k_value <- c()\n",
    "kernel_value <- c()\n",
    "pred <- rep(0, nrow(full_data))\n",
    "\n",
    "\n",
    "for (m in 1:length(different_kernel_list)){\n",
    "    for (i in 1:length(k_list)) {\n",
    "        for (j in 1:nrow(full_data)) {\n",
    "            kknn_model <- kknn(R1~., full_data[-j,1:11], full_data[j,1:11], \n",
    "                               k = k_list[i], distance = 2, scale = TRUE,\n",
    "                               kernel = different_kernel_list[m])\n",
    "#             print(kknn_model)\n",
    "            pred[j] <- round(fitted(kknn_model))\n",
    "        }\n",
    "        accur = sum(pred == full_data[,11])/length(full_data[,11])\n",
    "#         prin(accur)\n",
    "        accuracy_value <- c(accuracy_value, accur)\n",
    "#         print(accuracy_value)\n",
    "        k_value <- c(k_value, k_list[i])\n",
    "#         print(k_value)\n",
    "        kernel_value <- c(kernel_value, different_kernel_list[m])\n",
    "#         print(kernel_value)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "df <- data.frame(kernel_value, k_value, accuracy_value*100)\n",
    "names(df) <- c(\"Kernel\",\"K Value\",\"Model Accuracy\")\n",
    "df3 <- df[order(df[\"Model Accuracy\"], decreasing = TRUE), ]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement: using cross-validation (do this for the k-nearest-neighbors model; SVM is optional)**\n",
    "\n",
    "###### Stepwise explanation to the problem approach:\n",
    "\n",
    "For this I train using train.knn approch to find the best k value and Kernel fuction.\n",
    "\n",
    "***train.kknn*** - Training of kknn method via leave-one-out crossvalidation.\n",
    "**From the train.kknn approach, attributes(model) shows that the Accuracy is 100%, Minimal mean squared error is 10.61155 % for k = 22 and for the \"inv\" Kernel.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***cv.kknn*** - k-fold cross-validation, where k is the number number of data points (I'm using 15). Cross validates 1 row with k-1 rows.\n",
    "**From the cv.kknn approach, attributes(model) shows that the Model accuracy is 86.08563 % for k = 39 and for the \"optimal\" Kernel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Start of training kknn method-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = R1 ~ ., data = full_data, kmax = 101, distance = 2,     kernel = kernels, scale = TRUE)\n",
       "\n",
       "Type of response variable: continuous\n",
       "minimal mean absolute error: 0.1850153\n",
       "Minimal mean squared error: 0.1061155\n",
       "Best kernel: inv\n",
       "Best k: 22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Kernel is: inv , Best K Value is: 22 , and the accuracy is: 100 %\n",
      "\n",
      "-------------End of training the kknn method-------------\n",
      "\n",
      "-------------Start of cross-validation for kknn method-------------\n",
      "\n",
      "For rectangular kernel, model accuracy is: 84.86239 % and corresponding k-value is: 39\n",
      "For triangular kernel, model accuracy is: 85.3211 % and corresponding k-value is: 39\n",
      "For epanechnikov kernel, model accuracy is: 85.3211 % and corresponding k-value is: 39\n",
      "For biweight kernel, model accuracy is: 85.47401 % and corresponding k-value is: 39\n",
      "For triweight kernel, model accuracy is: 85.93272 % and corresponding k-value is: 39\n",
      "For cos kernel, model accuracy is: 86.08563 % and corresponding k-value is: 39\n",
      "For inv kernel, model accuracy is: 86.08563 % and corresponding k-value is: 39\n",
      "For gaussian kernel, model accuracy is: 86.08563 % and corresponding k-value is: 39\n",
      "For optimal kernel, model accuracy is: 86.08563 % and corresponding k-value is: 39\n",
      "\n",
      "-------------End of the cross-validation for kknn method-------------\n"
     ]
    }
   ],
   "source": [
    "library(kernlab)\n",
    "library(kknn)\n",
    "library(data.table)\n",
    "library(e1071)\n",
    "library(caTools)\n",
    "require(caTools)\n",
    "set.seed(101)\n",
    "\n",
    "full_data <- read.table(\"credit_card_data-headers.txt\", header = TRUE)\n",
    "kernels = c(\"rectangular\", \"triangular\", \"epanechnikov\", \"biweight\", \"triweight\", \"cos\", \"inv\", \"gaussian\", \"optimal\")\n",
    "\n",
    "cat(\"-------------Start of training kknn method-------------\\n\")\n",
    "\n",
    "train_model <- train.kknn(R1~., full_data, kmax = 101, distance = 2, kernel = kernels, scale = TRUE)\n",
    "train_model\n",
    "best_train_kernel <- train_model$best.parameters$kernel # We are finding the best kernel factor \n",
    "best_train_kvalue <- train_model$best.parameters$k # We are finding the best kvalue for the model \n",
    "\n",
    "kknn_train_model <- train.kknn(R1~., full_data, ks=best_train_kvalue, distance = 2,\n",
    "                               kernel = best_train_kernel, scale = TRUE)\n",
    "# print(kknn_train_model)\n",
    "pred <- round(predict(kknn_train_model, full_data[,1:10]))\n",
    "# print(pred)\n",
    "train_model_accuracy <- sum(pred == full_data[,11])/length(full_data[,11])\n",
    "# print(train_model_accuracy)\n",
    "cat(\"\\nBest Kernel is:\",best_train_kernel,\", Best K Value is:\",best_train_kvalue,\", and the accuracy is:\", \n",
    "    train_model_accuracy*100,\"%\\n\")\n",
    "\n",
    "\n",
    "\n",
    "cat(\"\\n-------------Start of cross-validation for kknn method-------------\\n\")\n",
    "\n",
    "kvals <- c(1:101)              \n",
    "model_accuracy <- c()\n",
    "\n",
    "for (i in 1:length(kernels)){\n",
    "    for (j in 1:length(kvals)){\n",
    "        cv_model <- cv.kknn(R1~., data= full_data, kcv = 15, scale = TRUE, \n",
    "                            kernel = kernels[i], k = kvals[j])\n",
    "        cv_model <- data.table(cv_model[[1]])\n",
    "#         print(cv_model)\n",
    "        cv_model_accuracy <- sum(round(cv_model$yhat) == full_data$R1)/length(full_data$R1)\n",
    "#         print(cv_model_accuracy)\n",
    "        model_accuracy <- c(model_accuracy, cv_model_accuracy)\n",
    "#         print(model_accuracy)\n",
    "    }\n",
    "    cat(\"\\nFor\", kernels[i], \"kernel, model accuracy is:\", max(model_accuracy)*100,\n",
    "        \"% and corresponding k-value is:\", kvals[which.max(model_accuracy[1:length(kvals)])])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I split the data into 3 parts into train-valid-test (70-15-15). \n",
    "\n",
    "###### My understanding from the output:\n",
    "\n",
    "The TEST ACCURACY is maximum for \"85.75740%\" for \"vanilladot\" Kernel function and a Cost value of \"0.01\" which is higher than the TRAIN ACCURACY. So, now when I see the output of **\"anovadot\" Kernel function** with a **Cost value of \"1000\"** has a better output of **\"86.74699\" TEST ACCURACY that is less than the TRAIN ACCURACY of \"91.90372\"** as the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n",
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Kernel</th><th scope=col>Cost Value</th><th scope=col>Train Split %</th><th scope=col>Validate Split %</th><th scope=col>Test Split %</th><th scope=col>Train Accuracy %</th><th scope=col>Validate Accuracy %</th><th scope=col>Test Accuracy %</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>vanilladot</td><td>   0.01   </td><td>70        </td><td>15        </td><td>15        </td><td>85.12035  </td><td>85.71429  </td><td>88.75740  </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>anovadot  </td><td>1000.00   </td><td>70        </td><td>15        </td><td>15        </td><td>91.90372  </td><td>89.79592  </td><td>86.74699  </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>polydot   </td><td>   0.01   </td><td>70        </td><td>15        </td><td>15        </td><td>86.87090  </td><td>83.67347  </td><td>84.30233  </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>rbfdot    </td><td>1000.00   </td><td>70        </td><td>15        </td><td>15        </td><td>99.56236  </td><td>91.83673  </td><td>72.61905  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Kernel & Cost Value & Train Split \\% & Validate Split \\% & Test Split \\% & Train Accuracy \\% & Validate Accuracy \\% & Test Accuracy \\%\\\\\n",
       "\\hline\n",
       "\t1 & vanilladot &    0.01    & 70         & 15         & 15         & 85.12035   & 85.71429   & 88.75740  \\\\\n",
       "\t3 & anovadot   & 1000.00    & 70         & 15         & 15         & 91.90372   & 89.79592   & 86.74699  \\\\\n",
       "\t4 & polydot    &    0.01    & 70         & 15         & 15         & 86.87090   & 83.67347   & 84.30233  \\\\\n",
       "\t2 & rbfdot     & 1000.00    & 70         & 15         & 15         & 99.56236   & 91.83673   & 72.61905  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Kernel | Cost Value | Train Split % | Validate Split % | Test Split % | Train Accuracy % | Validate Accuracy % | Test Accuracy % |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | vanilladot |    0.01    | 70         | 15         | 15         | 85.12035   | 85.71429   | 88.75740   |\n",
       "| 3 | anovadot   | 1000.00    | 70         | 15         | 15         | 91.90372   | 89.79592   | 86.74699   |\n",
       "| 4 | polydot    |    0.01    | 70         | 15         | 15         | 86.87090   | 83.67347   | 84.30233   |\n",
       "| 2 | rbfdot     | 1000.00    | 70         | 15         | 15         | 99.56236   | 91.83673   | 72.61905   |\n",
       "\n"
      ],
      "text/plain": [
       "  Kernel     Cost Value Train Split % Validate Split % Test Split %\n",
       "1 vanilladot    0.01    70            15               15          \n",
       "3 anovadot   1000.00    70            15               15          \n",
       "4 polydot       0.01    70            15               15          \n",
       "2 rbfdot     1000.00    70            15               15          \n",
       "  Train Accuracy % Validate Accuracy % Test Accuracy %\n",
       "1 85.12035         85.71429            88.75740       \n",
       "3 91.90372         89.79592            86.74699       \n",
       "4 86.87090         83.67347            84.30233       \n",
       "2 99.56236         91.83673            72.61905       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(kernlab)\n",
    "library(e1071)\n",
    "library(caTools)\n",
    "require(caTools)\n",
    "set.seed(101)\n",
    "\n",
    "full_data <- read.table(\"credit_card_data-headers.txt\", header = TRUE)\n",
    "kernel_list = c(\"vanilladot\", \"rbfdot\", \"anovadot\", \"polydot\")\n",
    "\n",
    "train_test_split <- c(0.7,0.15,0.15)           #(Train-Validation-Test) split\n",
    "\n",
    "cost_value <- c()\n",
    "kernel_val <- c()\n",
    "train_frac_list <- c()\n",
    "validate_frac_list <- c()\n",
    "test_frac_list <- c()\n",
    "Train_Accuracy <- c()\n",
    "Validation_Accuracy <- c()\n",
    "Test_Accuracy <- c()\n",
    "\n",
    "for (k1 in 1:length(kernel_list)){\n",
    "\n",
    "#Spliting the Data into train, validation and test\n",
    "    Training_split <- train_test_split[1]\n",
    "    Validation_split <- train_test_split[2]\n",
    "    Test_split <- train_test_split[3]\n",
    "    \n",
    "    Training_SampleSize <- floor(Training_split * nrow(full_data))\n",
    "#     print(Training_SampleSize)\n",
    "    Validation_SampleSize <- floor(Validation_split * nrow(full_data))\n",
    "#     print(Validation_SampleSize)\n",
    "    Test_SampleSize <- floor(Test_split * nrow(full_data))\n",
    "#     print(Test_SampleSize)\n",
    "    \n",
    "    Training_index <- sort(sample(seq_len(nrow(full_data)), size=Training_SampleSize))\n",
    "    NotTraining_index <- setdiff(seq_len(nrow(full_data)), Training_index)\n",
    "    Validation_index <- sort(sample(indicesNotTraining, size=Validation_SampleSize))\n",
    "    Test_index <- setdiff(NotTraining_index, Validation_index)\n",
    " \n",
    "# Training Data\n",
    "    dfTraining <- full_data[Training_index, ]\n",
    "    x_dfTraining <- dfTraining[,1:10]\n",
    "    y_dfTraining <- dfTraining[,11]\n",
    "\n",
    "# Validation Data    \n",
    "    dfValidation <- full_data[Validation_index, ]\n",
    "    x_dfValidation <- dfValidation[,1:10]\n",
    "    y_dfValidation <- dfValidation[,11]\n",
    "    \n",
    "# Test Data \n",
    "    dfTest <- full_data[Test_index, ]\n",
    "    x_dfTest <- dfTest[,1:10]\n",
    "    y_dfTest <- dfTest[,11]\n",
    "    \n",
    "\n",
    "    cost_values <- c(0.001,0.01,0.1,1,10,100,1000)\n",
    "    train_accuracy <- c()\n",
    "    prediction_train <- c()\n",
    "    train_model <- c()\n",
    "    \n",
    "    for (i in 1:length(cost_values)){\n",
    "        ksvm_model <- ksvm(as.matrix(x_dfTraining), as.factor(y_dfTraining), \n",
    "                           type = \"C-svc\", kernel = kernel_list[k1],\n",
    "                           C = cost_values[i], scaled = TRUE)\n",
    "        a <- colSums(ksvm_model@xmatrix[[1]]*ksvm_model@coef[[1]])\n",
    "        a0 <- ksvm_model@b\n",
    "        accuracy <- sum(predict(ksvm_model,x_dfTraining) == y_dfTraining)/length(y_dfTraining)\n",
    "        train_accuracy <- c(train_accuracy,accuracy)\n",
    "        train_model <- c(train_model, ksvm_model)\n",
    "        prediction_train <- c(prediction_train, predict(ksvm_model,x_dfTraining))\n",
    "    }\n",
    "    \n",
    "    model <- train_model[which.max(train_accuracy[1:length(cost_values)])]\n",
    "    C_val = cost_values[which.max(train_accuracy[1:length(cost_values)])]\n",
    "    train_accuracy <- max(train_accuracy[1:length(cost_values)])\n",
    "    validation_predict <- predict(model[[1]],x_dfValidation)\n",
    "    validation_accuracy <- sum(validation_predict == y_dfValidation)/length(y_dfValidation)\n",
    "    test_predict <- predict(model[[1]],x_dfTest)\n",
    "    test_accuracy <- sum(test_predict == y_dfTest)/length(y_dfTest)\n",
    "    Train_Accuracy <- c(Train_Accuracy, train_accuracy)\n",
    "    Validation_Accuracy <- c(Validation_Accuracy, validation_accuracy)\n",
    "    Test_Accuracy <- c(Test_Accuracy, test_accuracy)\n",
    "    cost_value <- c(cost_value, C_val)\n",
    "    train_frac_list <- c(train_frac_list, Training_split*100)\n",
    "    validate_frac_list <- c(validate_frac_list, Validation_split*100)\n",
    "    test_frac_list <- c(test_frac_list, Test_split*100)\n",
    "    kernel_val <- c(kernel_val, kernel_list[k1])\n",
    "}\n",
    "\n",
    "df <- data.frame(kernel_val, cost_value, train_frac_list, validate_frac_list, \n",
    "                 test_frac_list, Train_Accuracy*100, \n",
    "                 Validation_Accuracy*100, Test_Accuracy*100)\n",
    "names(df) <- c(\"Kernel\",\"Cost Value\",\"Train Split %\",\"Validate Split %\",\"Test Split %\", \n",
    "               \"Train Accuracy %\",\n",
    "               \"Validate Accuracy %\",\"Test Accuracy %\")\n",
    "\n",
    "df4 <- df[order(df[\"Test Accuracy %\"], decreasing = TRUE), ]\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
